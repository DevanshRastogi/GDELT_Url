import csv
import re
import pandas as pd

# Function to extract URLs from a text
def extract_urls(text):
    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
    return re.findall(url_pattern, text)

# CSV file path for input
input_csv_file_path = '20130401.export.CSV'

# Create a list to store extracted URLs
all_urls = []

# Open and read the input CSV file
with open(input_csv_file_path, 'r', encoding='utf-8') as csv_file:
    csv_reader = csv.reader(csv_file)
    
    # Assuming the first row contains column headers, you can skip it using next()
    next(csv_reader)
    
    # Iterate through each row in the CSV file
    for row in csv_reader:
        for cell in row:
            urls_in_cell = extract_urls(cell)  # Extract URLs from the cell
            all_urls.extend(urls_in_cell)

# CSV file path for output
output_csv_file_path = 'output_urls.csv'

# Write the extracted URLs to an output CSV file
with open(output_csv_file_path, 'w', newline='', encoding='utf-8') as output_csv_file:
    csv_writer = csv.writer(output_csv_file)
    
    # Write a header row
    csv_writer.writerow(['Extracted URLs'])
    
    # Write the extracted URLs
    for url in all_urls:
        csv_writer.writerow([url])

print(f'URLs saved to {output_csv_file_path}')
